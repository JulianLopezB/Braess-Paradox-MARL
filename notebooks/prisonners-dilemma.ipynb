{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5439fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import os\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1dcc3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEnv(gym.Env):\n",
    "    \n",
    "    \"\"\"Custom Environment that follows gym interface\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, k_init):\n",
    "        super(CustomEnv, self).__init__()\n",
    "        self.r = 0.01\n",
    "        self.k_init = k_init\n",
    "        self.c_space = spaces.Box(low=np.array([0]), high=np.array([100]))\n",
    "        self.k_space = spaces.Box(low=np.array([0]), high=np.array([100]))\n",
    "    \n",
    "    def utility(self, c):\n",
    "        return 1 + c\n",
    "        \n",
    "    def reset(self):\n",
    "        self.k = self.k_init\n",
    "        self.done = False\n",
    "        return self.k\n",
    "    \n",
    "    def step(self, c):\n",
    "        self.k = (1+self.r) * self.k - c\n",
    "        if self.k <=0: self.done = True\n",
    "        return self.k, self.utility(c), self.done\n",
    "\n",
    "    \n",
    "    def render(self, mode='human', close=False):\n",
    "        # Render the environment to the screen\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "36989c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, max_size, input_shape, n_actions):\n",
    "        self.mem_size = max_size\n",
    "        self.mem_cntr = 0\n",
    "        self.state_memory = np.zeros((self.mem_size, input_shape),\n",
    "                                     dtype=np.float32)\n",
    "        self.new_state_memory = np.zeros((self.mem_size, input_shape),\n",
    "                                         dtype=np.float32)\n",
    "\n",
    "        self.action_memory = np.zeros(self.mem_size, dtype=np.int64)\n",
    "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n",
    "\n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        index = self.mem_cntr % self.mem_size\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.action_memory[index] = action\n",
    "        self.reward_memory[index] = reward\n",
    "        self.terminal_memory[index] = done\n",
    "        self.mem_cntr += 1\n",
    "\n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "        batch = np.random.choice(max_mem, batch_size, replace=False)\n",
    "\n",
    "        states = self.state_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        states_ = self.new_state_memory[batch]\n",
    "        terminal = self.terminal_memory[batch]\n",
    "\n",
    "        return states, actions, rewards, states_, terminalZ\n",
    "    \n",
    "    \n",
    "class DeepQNetwork(nn.Module):\n",
    "    def __init__(self, lr, n_actions, name, input_dims, chkpt_dir):\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        self.checkpoint_dir = chkpt_dir\n",
    "        self.checkpoint_file = os.path.join(self.checkpoint_dir, name)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(input_dims, 32, 8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, stride=1)\n",
    "\n",
    "        fc_input_dims = self.calculate_conv_output_dims(input_dims)\n",
    "\n",
    "        self.fc1 = nn.Linear(fc_input_dims, 512)\n",
    "        self.fc2 = nn.Linear(512, n_actions)\n",
    "\n",
    "        self.optimizer = optim.RMSprop(self.parameters(), lr=lr)\n",
    "\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def calculate_conv_output_dims(self, input_dims):\n",
    "        state = T.zeros(1, input_dims)\n",
    "        dims = self.conv1(state)\n",
    "        dims = self.conv2(dims)\n",
    "        dims = self.conv3(dims)\n",
    "        return int(np.prod(dims.size()))\n",
    "\n",
    "    def forward(self, state):\n",
    "        conv1 = F.relu(self.conv1(state))\n",
    "        conv2 = F.relu(self.conv2(conv1))\n",
    "        conv3 = F.relu(self.conv3(conv2))\n",
    "        conv_state = conv3.view(conv3.size()[0], -1)\n",
    "\n",
    "        flat1 = F.relu(self.fc1(conv_state))\n",
    "        actions = self.fc2(flat1)\n",
    "\n",
    "        return actions\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        print('... saving checkpoint ...')\n",
    "        T.save(self.state_dict(), self.checkpoint_file)\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        print('... loading checkpoint ...')\n",
    "        self.load_state_dict(T.load(self.checkpoint_file))\n",
    "\n",
    "\n",
    "\n",
    "class DQNAgent(object):\n",
    "    def __init__(self, gamma, epsilon, lr, n_actions, input_dims,\n",
    "                 mem_size, batch_size, eps_min=0.01, eps_dec=5e-7,\n",
    "                 replace=1000, algo=None, env_name=None, chkpt_dir='tmp/dqn'):\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.lr = lr\n",
    "        self.n_actions = n_actions\n",
    "        self.input_dims = input_dims\n",
    "        self.batch_size = batch_size\n",
    "        self.eps_min = eps_min\n",
    "        self.eps_dec = eps_dec\n",
    "        self.replace_target_cnt = replace\n",
    "        self.algo = algo\n",
    "        self.env_name = env_name\n",
    "        self.chkpt_dir = chkpt_dir\n",
    "        self.action_space = [i for i in range(n_actions)]\n",
    "        self.learn_step_counter = 0\n",
    "\n",
    "        self.memory = ReplayBuffer(mem_size, input_dims, n_actions)\n",
    "\n",
    "        self.q_eval = DeepQNetwork(self.lr, self.n_actions,\n",
    "                                    input_dims=self.input_dims,\n",
    "                                    name=self.env_name+'_'+self.algo+'_q_eval',\n",
    "                                    chkpt_dir=self.chkpt_dir)\n",
    "\n",
    "        self.q_next = DeepQNetwork(self.lr, self.n_actions,\n",
    "                                    input_dims=self.input_dims,\n",
    "                                    name=self.env_name+'_'+self.algo+'_q_next',\n",
    "                                    chkpt_dir=self.chkpt_dir)\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        if np.random.random() > self.epsilon:\n",
    "            state = T.tensor([observation],dtype=T.float).to(self.q_eval.device)\n",
    "            actions = self.q_eval.forward(state)\n",
    "            action = T.argmax(actions).item()\n",
    "        else:\n",
    "            action = np.random.choice(self.action_space)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        self.memory.store_transition(state, action, reward, state_, done)\n",
    "\n",
    "    def sample_memory(self):\n",
    "        state, action, reward, new_state, done = \\\n",
    "                                self.memory.sample_buffer(self.batch_size)\n",
    "\n",
    "        states = T.tensor(state).to(self.q_eval.device)\n",
    "        rewards = T.tensor(reward).to(self.q_eval.device)\n",
    "        dones = T.tensor(done).to(self.q_eval.device)\n",
    "        actions = T.tensor(action).to(self.q_eval.device)\n",
    "        states_ = T.tensor(new_state).to(self.q_eval.device)\n",
    "\n",
    "        return states, actions, rewards, states_, dones\n",
    "\n",
    "    def replace_target_network(self):\n",
    "        if self.learn_step_counter % self.replace_target_cnt == 0:\n",
    "            self.q_next.load_state_dict(self.q_eval.state_dict())\n",
    "\n",
    "    def decrement_epsilon(self):\n",
    "        self.epsilon = self.epsilon - self.eps_dec \\\n",
    "                           if self.epsilon > self.eps_min else self.eps_min\n",
    "\n",
    "    def save_models(self):\n",
    "        self.q_eval.save_checkpoint()\n",
    "        self.q_next.save_checkpoint()\n",
    "\n",
    "    def load_models(self):\n",
    "        self.q_eval.load_checkpoint()\n",
    "        self.q_next.load_checkpoint()\n",
    "\n",
    "    def learn(self):\n",
    "        if self.memory.mem_cntr < self.batch_size:\n",
    "            return\n",
    "\n",
    "        self.q_eval.optimizer.zero_grad()\n",
    "\n",
    "        self.replace_target_network()\n",
    "\n",
    "        states, actions, rewards, states_, dones = self.sample_memory()\n",
    "        indices = np.arange(self.batch_size)\n",
    "\n",
    "        q_pred = self.q_eval.forward(states)[indices, actions]\n",
    "        q_next = self.q_next.forward(states_).max(dim=1)[0]\n",
    "\n",
    "        q_next[dones] = 0.0\n",
    "        q_target = rewards + self.gamma*q_next\n",
    "\n",
    "        loss = self.q_eval.loss(q_target, q_pred).to(self.q_eval.device)\n",
    "        loss.backward()\n",
    "        self.q_eval.optimizer.step()\n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "        self.decrement_epsilon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a92f1ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = CustomEnv(k_init=1)\n",
    "env.reset()\n",
    "env.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6b67ec45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.k_space.high[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b0003afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.51 1.5 False\n"
     ]
    }
   ],
   "source": [
    "c = 0.5\n",
    "k, u, done = env.step(c)\n",
    "print(k, u, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49189498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = CustomEnv(k_init=1)\n",
    "# env.reset()\n",
    "\n",
    "# best_score = -np.inf\n",
    "# load_checkpoint = False\n",
    "# n_games = 250\n",
    "\n",
    "# agent = DQNAgent(gamma=0.99, epsilon=1, lr=0.0001,\n",
    "#                  input_dims=int(env.k_space.high),\n",
    "#                  n_actions=int(env.c_space.high), mem_size=50000, eps_min=0.1,\n",
    "#                  batch_size=32, replace=1000, eps_dec=1e-5,\n",
    "#                  chkpt_dir='models/', algo='DQNAgent',\n",
    "#                  env_name='PongNoFrameskip-v4')\n",
    "\n",
    "# if load_checkpoint:\n",
    "#     agent.load_models()\n",
    "\n",
    "# fname = agent.algo + '_' + agent.env_name + '_lr' + str(agent.lr) +'_' \\\n",
    "#         + str(n_games) + 'games'\n",
    "# figure_file = 'plots/' + fname + '.png'\n",
    "\n",
    "# # if you want to record video of your agent playing, do a mkdir tmp && mkdir tmp/dqn-video\n",
    "# # and uncomment the following 2 lines.\n",
    "# #env = wrappers.Monitor(env, \"tmp/dqn-video\",\n",
    "# #                    video_callable=lambda episode_id: True, force=True)\n",
    "\n",
    "# n_steps = 0\n",
    "# scores, eps_history, steps_array = [], [], []\n",
    "\n",
    "# for i in range(n_games):\n",
    "#     done = False\n",
    "#     observation = env.reset()\n",
    "\n",
    "#     score = 0\n",
    "#     while not done:\n",
    "#         action = agent.choose_action(observation)\n",
    "#         observation_, reward, done, info = env.step(action)\n",
    "#         score += reward\n",
    "\n",
    "#         if not load_checkpoint:\n",
    "#             agent.store_transition(observation, action,\n",
    "#                                  reward, observation_, done)\n",
    "#             agent.learn()\n",
    "#         observation = observation_\n",
    "#         n_steps += 1\n",
    "#     scores.append(score)\n",
    "#     steps_array.append(n_steps)\n",
    "\n",
    "#     avg_score = np.mean(scores[-100:])\n",
    "#     print('episode: ', i,'score: ', score,\n",
    "#          ' average score %.1f' % avg_score, 'best score %.2f' % best_score,\n",
    "#         'epsilon %.2f' % agent.epsilon, 'steps', n_steps)\n",
    "\n",
    "#     if avg_score > best_score:\n",
    "#         if not load_checkpoint:\n",
    "#             agent.save_models()\n",
    "#         best_score = avg_score\n",
    "\n",
    "#     eps_history.append(agent.epsilon)\n",
    "\n",
    "# x = [i+1 for i in range(len(scores))]\n",
    "# plot_learning_curve(steps_array, scores, eps_history, figure_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd2b0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((1, 100),  dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c80c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrisonnersDilemma(gym.Env):\n",
    "    \n",
    "    \"\"\"Custom Environment that follows gym interface\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PrisonnersDilemma, self).__init__()\n",
    "        self.n_agents = 2\n",
    "        self.n_actions = 2\n",
    "        self.n_states = 5 # (0: initial, 1: (0,0), 2: (1,0), 3: (0,1), 4: (1,1)\n",
    "        self.n_games = 10\n",
    "        #self.action_space = spaces.Discrete(self.n_actions)\n",
    "        #self.observation_space = spaces.Discrete(self.n_states)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state = 0\n",
    "        self.game = 0\n",
    "        self.done = False\n",
    "        return self.state\n",
    "    \n",
    "    def step(self, actions):\n",
    "        \n",
    "        actions = [0]\n",
    "        \n",
    "        if actions == [0, 0]:\n",
    "            rewards = [1, 1]\n",
    "            self.state = 1\n",
    "            \n",
    "        elif actions == [1, 0]:\n",
    "            rewards = [0, 3]\n",
    "            self.state = 2\n",
    "            \n",
    "        elif actions == [0, 1]:\n",
    "            rewards = [3, 0]\n",
    "            self.state = 3     \n",
    "\n",
    "        else:\n",
    "            rewards = [2, 2]\n",
    "            self.state = 4\n",
    "            \n",
    "        \n",
    "        self.game +=1\n",
    "        \n",
    "        if self.game == self.n_games:\n",
    "            self.state = 0\n",
    "            self.done = True\n",
    "            \n",
    "        info = {}\n",
    "            \n",
    "        return self.state, rewards, self.done, info\n",
    "\n",
    "    \n",
    "    def render(self, mode='human', close=False):\n",
    "        # Render the environment to the screen\n",
    "        pass\n",
    "\n",
    "    \n",
    "# class Q_Agent():\n",
    "#     def __init__(self, lr, gamma, eps_start, eps_end, eps_dec, n_actions, n_states):\n",
    "        \n",
    "#         self.lr = lr\n",
    "#         self.gamma = gamma\n",
    "#         self.epsilon = eps_start\n",
    "#         self.eps_min = eps_end\n",
    "#         self.eps_dec = eps_dec\n",
    "        \n",
    "#         self.n_actions = n_actions\n",
    "#         self.n_states = n_states\n",
    "        \n",
    "#         self.Q = {}\n",
    "#         #self.q_table = np.zeros(env.n_actions)\n",
    "    \n",
    "#     def policy_fn(self):\n",
    "        \n",
    "    \n",
    "#     def select_action(self):\n",
    "#         pass\n",
    "    \n",
    "\n",
    "class QAgent():\n",
    "    def __init__(self, lr, gamma, n_actions, n_states, eps_start, eps_end, eps_dec):\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.n_actions = n_actions\n",
    "        self.n_states = n_states\n",
    "        self.epsilon = eps_start\n",
    "        self.eps_min = eps_end\n",
    "        self.eps_dec = eps_dec\n",
    "\n",
    "        self.Q = {}\n",
    "\n",
    "        self.init_Q()\n",
    "\n",
    "    def init_Q(self):\n",
    "        for state in range(self.n_states):\n",
    "            for action in range(self.n_actions):\n",
    "                self.Q[(state, action)] = 0.0\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = np.random.choice([i for i in range(self.n_actions)])\n",
    "        else:\n",
    "            actions = np.array([self.Q[(state, a)] \\\n",
    "                                for a in range(self.n_actions)])\n",
    "            action = np.argmax(actions)\n",
    "        return action\n",
    "\n",
    "    def decrement_epsilon(self):\n",
    "        self.epsilon = self.epsilon*self.eps_dec if self.epsilon>self.eps_min\\\n",
    "                       else self.eps_min\n",
    "\n",
    "    def learn(self, state, action, reward, state_):\n",
    "        actions = np.array([self.Q[(state_, a)] for a in range(self.n_actions)])\n",
    "        a_max = np.argmax(actions)\n",
    "\n",
    "        self.Q[(state, action)] += self.lr*(reward +\n",
    "                                        self.gamma*self.Q[(state_, a_max)] -\n",
    "                                        self.Q[(state, action)])\n",
    "        self.decrement_epsilon()\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "          nn.Linear(env.observation_space.n, 20),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(20, 20),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(20, env.action_space.n)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def act(self, state, epsilon):\n",
    "        if random.random() > epsilon:\n",
    "            state = Variable(torch.FloatTensor(state).unsqueeze(0)) \n",
    "            q_value = self.forward(state)\n",
    "            action  = q_value.max(1)[1]\n",
    "        else:\n",
    "            action = random.randrange(env.action_space.n)\n",
    "        return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7764832",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/by/t7qyz4pn5jsg1132688qnk780000gn/T/ipykernel_95842/2865343815.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "input_shape = int(env.c_space.high)\n",
    "np.zeros((1, input_shape), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e848d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = PrisonnersDilemma()\n",
    "env.reset()\n",
    "env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "122e0e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [2, 2] False 1\n"
     ]
    }
   ],
   "source": [
    "actions = [0, 0]\n",
    "new_state, rewards, done, info = env.step(actions)\n",
    "print(new_state, rewards, done, env.game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f48ab18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [2, 2] False 2\n",
      "4 [2, 2] False 3\n"
     ]
    }
   ],
   "source": [
    "actions = [1, 0]\n",
    "new_state, rewards, done, info = env.step(actions)\n",
    "print(new_state, rewards, done, env.game)\n",
    "\n",
    "actions = [0, 1]\n",
    "new_state, rewards, done, info = env.step(actions)\n",
    "print(new_state, rewards, done, env.game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eefbff62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [2, 2] False 4\n"
     ]
    }
   ],
   "source": [
    "actions = [1, 1]\n",
    "new_state, rewards, done, info = env.step(actions)\n",
    "print(new_state, rewards, done, env.game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e656d806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ad4ebba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97707ab52d6d4f1f9e71b5c833f16fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  0 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.95\n",
      "episode  100 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.01\n",
      "episode  200 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  300 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  400 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  500 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  600 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  700 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  800 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  900 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  1000 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  1100 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  1200 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  1300 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  1400 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  1500 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  1600 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  1700 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  1800 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  1900 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  2000 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  2100 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  2200 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  2300 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  2400 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  2500 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  2600 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  2700 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  2800 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  2900 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  3000 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  3100 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  3200 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  3300 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  3400 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  3500 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  3600 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  3700 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  3800 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  3900 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  4000 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  4100 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  4200 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  4300 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  4400 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  4500 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  4600 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  4700 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  4800 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  4900 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  5000 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  5100 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  5200 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  5300 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  5400 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  5500 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  5600 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  5700 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  5800 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  5900 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  6000 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  6100 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  6200 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  6300 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  6400 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  6500 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  6600 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  6700 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  6800 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  6900 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  7000 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  7100 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  7200 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  7300 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  7400 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  7500 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  7600 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  7700 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  7800 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  7900 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  8000 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  8100 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  8200 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  8300 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  8400 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  8500 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  8600 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  8700 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  8800 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  8900 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  9000 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  9100 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  9200 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  9300 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  9400 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  9500 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  9600 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  9700 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  9800 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  9900 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  10000 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  10100 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  10200 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  10300 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  10400 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  10500 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  10600 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  10700 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  10800 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  10900 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  11000 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  11100 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  11200 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  11300 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  11400 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  11500 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  11600 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  11700 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  11800 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  11900 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  12000 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  12100 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  12200 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n",
      "episode  12300 \n",
      " Mean Reward Agent 1 20.00 \n",
      " Mean Reward Agent 2 20.00 \n",
      " epsilon 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/by/t7qyz4pn5jsg1132688qnk780000gn/T/ipykernel_95842/2196390953.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mobservation_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/by/t7qyz4pn5jsg1132688qnk780000gn/T/ipykernel_95842/2196390953.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mobservation_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/by/t7qyz4pn5jsg1132688qnk780000gn/T/ipykernel_95842/2310967293.py\u001b[0m in \u001b[0;36mchoose_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    103\u001b[0m             actions = np.array([self.Q[(state, a)] \\\n\u001b[1;32m    104\u001b[0m                                 for a in range(self.n_actions)])\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m     \"\"\"\n\u001b[0;32m-> 1188\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = PrisonnersDilemma()\n",
    "n_games = 10\n",
    "n_agents = env.n_agents\n",
    "n_states = env.n_states\n",
    "n_actions = env.n_actions\n",
    "env.n_games = n_games\n",
    "params = {'lr': 0.005, \n",
    "          'gamma': 0.999, \n",
    "          'eps_start': 1.0, \n",
    "          'eps_end': 0.001,\n",
    "          'eps_dec': 0.995, \n",
    "          'n_actions': n_actions, \n",
    "          'n_states': n_states}\n",
    "\n",
    "agents = [QAgent(**params) for i in range(env.n_agents)]\n",
    "\n",
    "scores = defaultdict(list)\n",
    "win_pct_list = []\n",
    "n_episodes = 100000\n",
    "cooperations = []\n",
    "qvalues = []\n",
    "actions_list = []\n",
    "\n",
    "for i_episode in tqdm(range(n_episodes)):\n",
    "    \n",
    "    \n",
    "    actions_episode = []\n",
    "    done = False\n",
    "    observation = env.reset()\n",
    "    scores_episode = defaultdict(int)\n",
    "    n_coops = 0\n",
    "    \n",
    "    while not done:\n",
    "        \n",
    "        actions = [agent.choose_action(observation) for agent in agents]\n",
    "        observation_, rewards, done, info = env.step(actions)\n",
    "        \n",
    "        \n",
    "        if observation_ == 4:\n",
    "            n_coops += 1\n",
    "       #print(observation_)\n",
    "        \n",
    "        for i_agent in range(n_agents):\n",
    "            agents[i_agent].learn(observation, actions[i_agent], rewards[i_agent], observation_)\n",
    "            scores_episode[i_agent] += rewards[i_agent]\n",
    "            \n",
    "        observation = observation_\n",
    "    \n",
    "        \n",
    "        actions_episode.append(actions)\n",
    "    actions_list.append(actions_episode)\n",
    "    qvalues.append(agents[0].Q)\n",
    "    for i_agent in range(n_agents):\n",
    "        scores[i_agent].append(scores_episode[i_agent])\n",
    "        \n",
    "    cooperations.append(n_coops/env.n_games)\n",
    "    \n",
    "    if i_episode % 100 == 0:\n",
    "        \n",
    "        win_pct = [np.mean(scores[i][-100:]) for i in range(n_agents)]\n",
    "        print('episode ', i_episode, \n",
    "              '\\n Mean Reward Agent 1 %.2f' % win_pct[0],\n",
    "              '\\n Mean Reward Agent 2 %.2f' % win_pct[1],\n",
    "              '\\n epsilon %.2f' % agents[0].epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50923f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e7974a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12cda3a60>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([x/n_games for x in scores[0]])\n",
    "plt.plot([x/n_games for x in scores[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "364deb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ef14c4b31a4b48b229ceddad64e6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eaa1b1df8e749c3ad81b9d617b6fc70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12b9f66a0>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([np.mean(scores[0][:i]) for i in tqdm(range(n_episodes))])\n",
    "plt.plot([np.mean(scores[1][:i]) for i in tqdm(range(n_episodes))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac160d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc11589984514ddf85e97ec4c5f20cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca54aa158de942539dde6f75a1362a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([np.mean([x/n_games for x in scores[0]][i-n_games:i]) for i in tqdm(range(n_episodes))])\n",
    "plt.plot([np.mean([x/n_games for x in scores[1]][i-n_games:i]) for i in tqdm(range(n_episodes))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b8f5465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881ba2bdc152442896025bd30ec1ccf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12cdaaa90>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVlklEQVR4nO3df5Bd5X3f8fd3dyVsfiSA2UkVSSDRqpmqTeofG4wb1/akxAYnEZ3YmYpJJji1h2kaJnbdaQvjhKZ0OomxhySOlRiN7YbxxMaOm3EVR4maYNqJExuzhB9GBhmBAUk2RiBAIEDS7n77xz0r3bu6q71a3bvnPmffr5mdvefHnuc557n3s+c+51dkJpKk8o3UXQFJUn8Y6JLUEAa6JDWEgS5JDWGgS1JDjNVV8AUXXJDr1q2rq3hJKtLdd9/9dGaOd5tWW6CvW7eOycnJuoqXpCJFxOPzTbPLRZIawkCXpIYw0CWpIQx0SWoIA12SGqKnQI+IyyNiV0Tsjojrukx/T0Tsj4h7q5/39b+qkqSTWfC0xYgYBbYAPwXsBe6KiG2Z+a05s34+M68dQB0lST3oZQ/9EmB3Zj6amUeA24ArB1ut+R06PMWX7tlXV/GSNLR6CfTVwJ624b3VuLneFRH3R8QXI2JttwVFxDURMRkRk/v3719EdeE3vvQAH/j8vfz9E88u6u8lqan6dVD0z4B1mfljwF8Bt3abKTO3ZuZEZk6Mj3e9cnVBTx58BYCXj0wvsqqS1Ey9BPo+oH2Pe0017pjMfCYzD1eDnwTe0J/qSZJ61Uug3wVsiIj1EbES2Axsa58hIla1DW4CHuxfFSVJvVjwLJfMnIqIa4EdwCjw6czcGRE3ApOZuQ34tYjYBEwBB4D3DLDOkqQuerrbYmZuB7bPGXdD2+vrgev7W7X56rIUpUhSeYq9UjTqroAkDZliA12S1MlAl6SGMNAlqSGKC/TEo6KS1E1xgX6MR0UlqUO5gS5J6mCgS1JDGOiS1BAGuiQ1RHGB7qX/ktRdcYE+KzzNRZI6FBvokqROBrokNYSBLkkNUVyge0xUkrorLtBnhcdEJalDsYEuSepUbKB7ProkdSou0O1pkaTuigt0d8wlqbviAn2WB0UlqVOxgS5J6mSgS1JDGOiS1BDlBbpHRSWpq/ICveIxUUnqVGygS5I6GeiS1BAGuiQ1hIEuSQ3RU6BHxOURsSsidkfEdSeZ710RkREx0b8qdkpPc5GkrhYM9IgYBbYAVwAbgasiYmOX+c4B3g/c2e9KzlOvpShGkorRyx76JcDuzHw0M48AtwFXdpnvvwMfBl7pY/1O8N3nWouffPzAIIuRpOL0EuirgT1tw3urccdExOuBtZn55ydbUERcExGTETG5f//+U64swL7nXgbgc994YlF/L0lNddoHRSNiBLgZ+I8LzZuZWzNzIjMnxsfHT7doSVKbXgJ9H7C2bXhNNW7WOcA/A/5vRDwGXApsG+SBUUnSiXoJ9LuADRGxPiJWApuBbbMTM/P5zLwgM9dl5jrg68CmzJwcSI0r4cX/ktRhwUDPzCngWmAH8CDwhczcGRE3RsSmQVdQktSbsV5mysztwPY5426YZ963nX61JEmnyitFJakhDHRJaggDXZIawkCXpIYw0CWpIQx0SWoIA12SGqLYQPfuuZLUqdhAT59zIUkdig10SVInA12SGsJAl6SGMNAlqSGKDXTPcpGkTuUGet0VkKQhU2ygS5I6FRvonoYuSZ2KDXRJUqdiA90+dEnqVGygS5I6GeiS1BAGuiQ1hIEuSQ1RbKCHl4pKUodiA12S1MlAl6SGMNAlqSEMdElqCANdkhrCQJekhugp0CPi8ojYFRG7I+K6LtP/XUR8MyLujYivRsTG/le1U6b3W5SkdgsGekSMAluAK4CNwFVdAvuzmfmjmfla4Cbg5r7XVJJ0Ur3soV8C7M7MRzPzCHAbcGX7DJl5sG3wLJbgduWHjkwPughJKspYD/OsBva0De8F3jh3poj4VeCDwErgJ7stKCKuAa4BuPDCC0+1rh32v3D4tP5ekpqmbwdFM3NLZv5D4L8Avz7PPFszcyIzJ8bHx/tVtCSJ3gJ9H7C2bXhNNW4+twH/+nQqJUk6db0E+l3AhohYHxErgc3AtvYZImJD2+BPAw/3r4qSpF4s2IeemVMRcS2wAxgFPp2ZOyPiRmAyM7cB10bEZcBR4Fng6kFWWpJ0ol4OipKZ24Htc8bd0Pb6/X2ulyTpFHmlqCQ1hIEuSQ1hoEtSQxjoktQQBrokNYSBLkkNYaBLUkMY6JLUEAa6JDWEgS5JDWGgS1JDGOiS1BAGuiQ1hIEuSQ1hoEtSQxjoktQQBrokNYSBLkkNYaBLUkMY6JLUEAa6JDVEcYEezPA/xj7Fj8QTdVdFkobKWN0VOFWr42l+Yex23jp6H/ArdVdHkoZGcXvoEHVXQJKGUoGBLknqprhAz6y7BpI0nMoL9KrLJTDZJamdgS5JDVFcoEuSuisu0C+MpwD44ThQc00kabgUF+gjMVN3FSRpKPUU6BFxeUTsiojdEXFdl+kfjIhvRcT9EXF7RFzU/6q2HM3RQS1akoq2YKBHxCiwBbgC2AhcFREb58x2DzCRmT8GfBG4qd8VnTVV3sWtkrQketlDvwTYnZmPZuYR4DbgyvYZMvOOzHypGvw6sKa/1TzuFVYOatGSVLReAn01sKdteG81bj7vBf6i24SIuCYiJiNicv/+/b3Xss2ubP2v+MzUZYv6e0lqqr4eFI2IXwQmgI90m56ZWzNzIjMnxsfHF1XGitFWl8sBfmCx1ZSkRuqlQ3ofsLZteE01rkNEXAZ8CHhrZh7uT/W6OHZvLi8skqR2veyh3wVsiIj1EbES2Axsa58hIl4H3AJsysyn+l/NtrKAmQyvFJWkORYM9MycAq4FdgAPAl/IzJ0RcWNEbKpm+whwNvAnEXFvRGybZ3F9kXgTXUmaq6dzADNzO7B9zrgb2l4v6RHKGUbcQ5ekOYq7UhRae+gjBrokdSgu0CNad1x0D12SOhUX6C1hH7okzVFkoM8QeNqiJHUqMtCTsA9dkuYoLtBne8/tQ5ekTsUFOnhQVJK6KTLQZzwoKkknKC7QIwCCEXxykSS1Ky7QwfNbJKmbQgPdPnRJmqu4QA9m+9ANdElqV16gR3geuiR1UVygZ6ZdLpLURXmBjvdDl6Ruigv0FuNckuYqLtDj2G+7XCSpXXGBDq3TFj0bXZI6FRrodrpI0lzFBfrsaYt2uUhSp/ICndkuF0lSu+ICfZaRLkmdigx0H3AhSScqNNDtQ5ekucoL9KgC3T4XSepQXqBX3EOXpE7FBXoAme6eS9JcxQX6ce6hS1K7IgPdK0Ul6USFBrpnuUjSXD0FekRcHhG7ImJ3RFzXZfpbIuLvI2IqIt7d/2p2MtAl6UQLBnpEjAJbgCuAjcBVEbFxzmxPAO8BPtvvCnapj1EuSV30sod+CbA7Mx/NzCPAbcCV7TNk5mOZeT8wM4A6dhXA9Ex90f7CK0d5YN/ztZU/n7sfP8DR6cE3w9T0DJOPHRh4OU13/97neOnI1JKXm5nc+egzZA7uM7TnwEvse+7loV1eE/US6KuBPW3De6txpywiromIyYiY3L9//2IWwUWvOfNYl8vvf+XhRS2jH9536yQ/8/tfZWoJwrNXO7/7PO/6w69x018+NPCyPvp/vs27P/E17t/73MDLaqrnXz7Kpo//Lb/2uXuXvOzPfuMJ/s3Wr/OXDzw5sDL+5U138BO//ZWhXV4TLelB0czcmpkTmTkxPj6+qGX8gx941bFAf/j7L/a5hr27+/FngeE6efLpF48A8NCTLwy8rF1PHqzKPDzwsprq8NFpAO6r4Z/id/YfAmDvs+7xNkkvgb4PWNs2vKYaV4uI4wdFcwjidIDfWIuw3Ne/H+rchsPwGVL/9BLodwEbImJ9RKwENgPbBlutk5uZDfQa34vL/V4ysdw3QD/UuAltvmZaMNAzcwq4FtgBPAh8ITN3RsSNEbEJICJ+PCL2Aj8P3BIROwdZ6SQYcc/iBH5GpeVtrJeZMnM7sH3OuBvaXt9FqytmSbT20Ifj675fWSUNi+KuFG1FeTCydGdISlIRigt0OL6HrvoNw7ckSS1FBnrrLJeZWrs7hvlfylKE7PCufTmOv4eW/n08e1Dbf8jNUmSgu4fenWcuSMtbkYGeVR/6MOxdDEMdJAkKDnR3RiWpU7GB7lkuw8EvKNLwKDLQZ6r981rDZIi/IizFwWL760/f7Daso9uuvsOxGqQiA32Y+tCXu0HefrXp3HTqtyID/fhZLn4iJGlWcYE+e7fFuu/lYo9Dawt4k67Fq3XT2WyNVFygQ3WWSwzH3vkwfW2u49wfu1yk4VFmoKcPiT4ZM7YMw3Bg0vdKsxQZ6MNwP/RZy/1ui8t77U+P2079VmSgJzCy7KNUkjoVGegzjNTe5bLcjwXOrv8y3wynpd5jorZcExUZ6FDtoQ9Bn8sQVOGYOv7JDNHqS8tekYE+DHvow2yY/slofsdvYVtfg9lx2SxFBnpC66Bo3RXBPVT/eSzeMHzDVLMUF+iZx/fQ/TxI0nHFBTocP8ulTsv9oNLs2i/3g8Ono86rbG23Zio00EeGp8tliL4m1PEZHaLVl5a9QgN9eM5yGUbD8a9OC/FKUfVbkYE+wwjDcjhyOGpRJ7fAYrnl1G9FBvow9KFL0rApNNCDDbGv1q+LdT5tZhh4UO30efdc9VuRgf6aOMgznGNfsSS1KTLQvz2zxj2Mbpb5t4ZS2V7qlyIDfYpRxpgejg/CMNRBRfKto34rMtAviu9zbhzijS/9v9rqcDH7uHXFbxPPPV5bHU6Qyc0r/oC3vPzXAy/q7OmD/NGKD/ODz9w38LKa7L+O3cov8udLXu6KmVf45IqPsObA1wdWxqaRv+X3Vny8b19B+r28Jioy0P/5yCMAvP3Qn9VWh5+LO3jr6P2seHjpP4zzGZk+zM+NfpVffe6jAy/rosO7eNvofVz80C0DL6vJfnlsB/8p/2jJyz338D4uG72HNz9y88DK+NjKLVw5+ndw5MWhXF4T9RToEXF5ROyKiN0RcV2X6WdExOer6XdGxLp+V7TdGNOtcpkZZDEnNTJb9hDtLcT04aUrq1rvkSUsU/0zOnMEgJXThwZf2FSf3yP9Xl6DLBjoETEKbAGuADYCV0XExjmzvRd4NjP/EfA7wIf7XdF2ozUG+XHDd1h2dObokpU1xtSSldVYWd/7eKx6r+RSvI8N9CUTC10+HxFvAn4zM99RDV8PkJm/1TbPjmqer0XEGPAkMJ4nWfjExEROTk6ecoXff9s9/PqDmxiPg0xnsGd0zSkvox/WTO9jLGZ4nnN4duTcWupwgukp1sX3AHhsZO1Aizpj+hCr4sCSlNVYmazLvcDSb8Ox6ZdZE08PtOx1M3sA2DeyiqOMDd3y6vTMGz7AG376fYv624i4OzMnuk3rZausBva0De8F3jjfPJk5FRHPA68Bnp5TkWuAawAuvPDCnio/12/+7D/l3ff9Br+z4g946cw1rByrZ0957+G1vPno3/HI2a+rpfxuMuGCF5/luysv4sUzfmigZR2ZSla98jfce+a/YGak7A9Xnc564QUOjZ7LgTMvWtJyp2eSNS/9Dd989Y9zdPTVAynjmYOv5p/E43z/zA1Dubw6rTz7/IEsd0k/iZm5FdgKrT30xSzjvLNWcvtvHfu/ULvX112BLv7xEpb12iUsq6nGgXU1lf2jS1BGvz8jw/iZGxa9HBTdB7R/J1tTjes6T9Xl8oPAM/2ooCSpN70E+l3AhohYHxErgc3AtjnzbAOurl6/G/jKyfrPJUn9t2CXS9Unfi2wAxgFPp2ZOyPiRmAyM7cBnwI+ExG7gQO0Ql+StIR66kPPzO3A9jnjbmh7/Qrw8/2tmiTpVBR5pagk6UQGuiQ1hIEuSQ1hoEtSQyx46f/ACo7YDyz23rMXMOcq1GXAdV4eXOfl4XTW+aLMHO82obZAPx0RMTnfvQyaynVeHlzn5WFQ62yXiyQ1hIEuSQ1RaqBvrbsCNXCdlwfXeXkYyDoX2YcuSTpRqXvokqQ5DHRJaojiAn2hB1aXIiLWRsQdEfGtiNgZEe+vxp8fEX8VEQ9Xv8+rxkdEfKxa7/sj4vVty7q6mv/hiLh6vjKHRUSMRsQ9EfHlanh99XDx3dXDxldW4+d9+HhEXF+N3xUR76hnTXoTEedGxBcj4qGIeDAi3tT0do6I/1C9rx+IiM9FxKua1s4R8emIeCoiHmgb17d2jYg3RMQ3q7/5WEQs/Hi2zCzmh9btex8BLgZWAvcBG+uu1yLXZRXw+ur1OcC3aT2E+ybgumr8dcCHq9fvBP6C1tOpLwXurMafDzxa/T6ven1e3eu3wLp/EPgs8OVq+AvA5ur1J4BfqV7/e+AT1evNwOer1xurtj8DWF+9J0brXq+TrO+twPuq1yuBc5vczrQeSfkd4NVt7fueprUz8BZaD1B6oG1c39oV+EY1b1R/e8WCdap7o5ziBnwTsKNt+Hrg+rrr1ad1+9/ATwG7gFXVuFXArur1LcBVbfPvqqZfBdzSNr5jvmH7ofXEq9uBnwS+XL1ZnwbG5rYxrXvwv6l6PVbNF3PbvX2+Yfuh9fSu71CdgDC3/ZrYzhx/xvD5Vbt9GXhHE9uZ1tMD2wO9L+1aTXuobXzHfPP9lNbl0u2B1atrqkvfVF8xXwfcCfxQZn6vmvQkMPu05/nWvbRt8rvAfwZmquHXAM9l5lQ13F7/joePA7MPHy9pndcD+4H/WXUzfTIizqLB7ZyZ+4CPAk8A36PVbnfT7Hae1a92XV29njv+pEoL9MaJiLOB/wV8IDMPtk/L1r/mxpxXGhE/AzyVmXfXXZclNEbra/kfZubrgEO0voof08B2Pg+4ktY/sx8GzgIur7VSNaijXUsL9F4eWF2MiFhBK8z/ODP/tBr9/YhYVU1fBTxVjZ9v3UvaJj8BbIqIx4DbaHW7/B5wbrQeLg6d9Z/v4eMlrfNeYG9m3lkNf5FWwDe5nS8DvpOZ+zPzKPCntNq+ye08q1/tuq96PXf8SZUW6L08sLoI1RHrTwEPZubNbZPaH7h9Na2+9dnxv1QdLb8UeL76arcDeHtEnFftGb29Gjd0MvP6zFyTmetotd1XMvMXgDtoPVwcTlznbg8f3wZsrs6OWA9soHUAaehk5pPAnoj4kWrUvwK+RYPbmVZXy6URcWb1Pp9d58a2c5u+tGs17WBEXFptw19qW9b86j6osIiDEO+kdUbII8CH6q7PaazHm2l9HbsfuLf6eSetvsPbgYeBvwbOr+YPYEu13t8EJtqW9W+B3dXPL9e9bj2u/9s4fpbLxbQ+qLuBPwHOqMa/qhreXU2/uO3vP1Rti130cPS/5nV9LTBZtfWXaJ3N0Oh2Bv4b8BDwAPAZWmeqNKqdgc/ROkZwlNY3sff2s12BiWr7PQJ8nDkH1rv9eOm/JDVEaV0ukqR5GOiS1BAGuiQ1hIEuSQ1hoEtSQxjoktQQBrokNcT/B5jMDsTNEHEOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cooperations)\n",
    "plt.plot([np.mean(cooperations[i-n_games:i]) for i in tqdm(range(n_episodes))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4802b5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e77089be5f4f1286d46cddc32f77ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def eff(score_1, score_2):\n",
    "    return (score_1 + score_2)/(4*n_games)\n",
    "    \n",
    "efficiency = [eff(scores[0][i], scores[1][i]) for i in tqdm(range(n_episodes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8b3c99a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d6dc8303994943875ac17af98ca0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x142ac3b50>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(efficiency)\n",
    "plt.plot([np.mean(efficiency[i-n_games:i]) for i in tqdm(range(n_episodes))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a907243d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.525, 0.525, 0.525, 0.525, 0.525, 0.525, 0.525, 0.525, 0.525, 0.525]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficiency[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a77b659b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0]],\n",
       " [[1, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0]],\n",
       " [[1, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0]],\n",
       " [[1, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0]],\n",
       " [[1, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0]],\n",
       " [[1, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0]],\n",
       " [[1, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0]],\n",
       " [[1, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0]],\n",
       " [[1, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0]],\n",
       " [[1, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0]]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_list[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "9bca08fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, -5, 2, 3])"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "ffed85d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Agent' object has no attribute 'select_action'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/by/t7qyz4pn5jsg1132688qnk780000gn/T/ipykernel_51453/3358440855.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Agent' object has no attribute 'select_action'"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    actions[i] = agent[i].select_action(state)\n",
    "\n",
    "new_state, rewards, done = env.step(actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41dbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
